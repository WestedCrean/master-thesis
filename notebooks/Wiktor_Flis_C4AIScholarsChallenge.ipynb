{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRUrAHlZKdWd"
      },
      "source": [
        "# C4AI Scholars Program Takehome Challenge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4wvFv6lTbY"
      },
      "source": [
        "### Background\n",
        "\n",
        "Welcome to the C4AI Scholars Program Take-Home Challenge! This exercise is designed to allow you to showcase your engineering and problem solving skills. The Challenge consists of three parts:\n",
        "\n",
        "* Part One of the challenge requires identifying bugs, and getting the code working. This is designed to test your ability to grapple with real world engineering challenges.\n",
        "* Part Two of the challenge tests your ability to generate code for a specified problem. \n",
        "* Part Three of the challenge is an opportunity for you to attempt an optional challenge question that extends the original problem set. \n",
        "\n",
        "\n",
        "These tasks were chosen as a setting to see how you think about problems, even if they are not in your own research field of interest. The tasks and dataset are not meant to be indicative of the research goals of the Scholar Program. We purposefully have selected a simple toy problem so the focus is on how you think, and does not require significant machine learning resources. \n",
        "\n",
        "Good luck! If you have questions about the framing of the questions, please contact info@for.ai  \n",
        "\n",
        "\n",
        "### How to Use and Submit this Document\n",
        "\n",
        "* **Make a copy of this document** and **rename** it **Firstname_Lastname_C4AIScholarsChallenge**\n",
        "* Once you‚Äôve completed all tasks, **save and pin your revisions**\n",
        "* **Submit a link** to your final document via the [Cohere For AI Scholars Program application](https://jobs.lever.co/cohere/?department=Cohere%20For%20AI). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmbPmOHhLx4U"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc-enDOhazoe"
      },
      "source": [
        "## Overview of Singular Value Decomposition\n",
        "\n",
        "In this takehome, you will be working on a problem involving singular value decomposition. Singular Value Decomposition (SVD) exists for every rectangular matrix. The nice thing about SVD is that the original matrix can be expressed as the sum of outer products of left and singular vectors scaled by the corresponding singular values. Formally:\n",
        "\n",
        "> Let ùõ¢ be a rectangular matrix of dimensions ùëöùòπùëõ, then the SVD of the matrix A is given by $ A = Uùõ¥V^T$ where $U$ is an orthogonal matrix of shape mxm containing the left singular vectors, $V$ is an orthogonal matrix of shape nxn containing the right singular vectors and $ùõ¥$ is a diagonal matrix containing the singular values of $A$. This formulation of SVD can be re-expressed as \\begin{align} A = \\sum_{i=1}^{r} s_i. u_i v_i^T \\end{align} where $r = \\text{min}(m,n)$ represents the rank of the matrix, $s_i$ is the $i$th singular value and $u_i v_i^T$ is the outer product of the $i$th left and right singular vectors. \n",
        "\n",
        "<!-- \\begin{align}\n",
        "A = \\sum_{i=1}^{\\text{min}(m,n)} s_i. u_i v_i^T\n",
        "\\end{align}\n",
        "\\begin{align} -->\n",
        "\n",
        "> The singular values $ùõ¥$ are decreasing in order. So, each outer product is scaled by a smaller value as we compute each term in the sum above. This gives us an opportunity to approximate $A$ using only the sum of the first $k$ outer products where $k < \\text{min}(m,n)$ $-$ this effectively means that we are zero-ing out some of the singular values by assuming that the contribution to the sum is negligible. This is called low-rank approximation.\n",
        "\n",
        "If you aren't familiar with singular value decomposition, or the above feels rusty, don't worry. Take a moment to brush up your knowledge using any of the following resources:\n",
        "* [stanford lecture notes on low rank approximations](https://web.stanford.edu/class/cs168/l/l9.pdf)\n",
        "* [youtube series of short and beginner friendly lectures](https://www.youtube.com/watch?v=gXbThCXjZFM&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcL7u9wJjPF3"
      },
      "source": [
        "## Check for understanding (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v-iHTH3nasL"
      },
      "source": [
        "#### Q1: What are some real world applications of low rank approximations?\n",
        "\n",
        "\n",
        "#### Answer: Topic modeling - using latent semantic indexing which incorporates SVD we can split documents into related keywords. Another one coming to my mind is splitting multi-dimensional vectors into principal components in PCA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHGqpn3tkFRL"
      },
      "source": [
        "#### Q2: What are the benefits of compressing a deep neural network? How would you measure the benefits of compression?\n",
        "\n",
        "\n",
        "#### Answer: Requiring less memory to do training/inference, important quality when doing transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9r4v5vng9ma"
      },
      "source": [
        "#### Q3: In this takehome, we will consider how singular value decomposition can be used to compress a deep neural network. Compared to other compression methods used for deep neural networks such as pruning, quantization, or efficient architectures, what are the relative merits/demerits of low rank approximations? Choose one or two alternative compression methods and compare with singular value decomposition.\n",
        "\n",
        "#### Answer: -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O81HH6D3Lugd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoWy4-iQIYJ0"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBFa6wXqAKgK",
        "outputId": "50f32d95-1e9d-48b9-a8ca-b86bd361b1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.8-py3-none-any.whl (350 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 350 kB 21.4 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 145 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.23)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.10.0)\n",
            "Installing collected packages: jmp, chex, optax, dm-haiku\n",
            "Successfully installed chex-0.1.5 dm-haiku-0.0.8 jmp-0.0.2 optax-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-haiku optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzdlf_milUbR"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator, Mapping, Tuple\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from absl import app\n",
        "import haiku as hk\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "import math\n",
        "\n",
        "Batch = Tuple[np.ndarray, np.ndarray]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsYJmUqz-uFT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTGxEfqnSmd"
      },
      "source": [
        "## Coding Challenge Part I : Debugging Challenge (10 Points)\n",
        "\n",
        "\n",
        "We are now going to explore using SVD to compute low rank approximations of the parameters of a small deep neural network. You are using a very simple toy model as a first baseline. Section 3 will give you the chance to improve baseline accuracy beyond this very simple model -- this is just a toy setting to first explore low rank approximations.\n",
        "\n",
        "The first part of this challenge is primarily a debugging challenge. It will require removing bugs in order to train a very simple network. We have introduced several bugs -- some are subtle and will not break your code but will degrade final performance. These subtle bugs are introduced to understand your grasp of fundamental machine learning principles. There are also more obvious bugs designed to break your code. \n",
        "\n",
        "* [**4 points**] Your goal is to get the code working. There are 4 bugs in the code, all 4 of these are subtle bugs which are designed to impair test accuracy but not break the code. You will get partial points for each of the 4 bugs you find. After finding all bugs, your test performance should be around 66-67% test accuracy. \n",
        "\n",
        "* [**2 points**] We will give extra points for also adding improved documentation to each of the functions we introduce in this section, and for describing the fixes to the bugs. \n",
        "\n",
        "* [**4 points**] There are also two functions you will need to code up in this section -- we indicate where these code changes need to happen with TODO comments. \n",
        "\n",
        "* Do not alter the model architecture or the learning rate.\n",
        "\n",
        "\n",
        "Useful tips:\n",
        "* To iterate faster and avoid training for 10000 steps each time you want to test whether you have found all the bugs, a good sign you have caught the bugs is wheter after 1000/10000 steps your accuracy >40%.\n",
        "* The colab difftool is useful to track what code you have changed during the debugging challenge (incase you need to revert code). You can access this via tools > diff notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqpgWQJs-evw"
      },
      "outputs": [],
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "\n",
        "def net_fn(batch: Batch) -> jnp.ndarray:\n",
        "\n",
        "  x = normalize(batch[0])\n",
        "  \n",
        "  # Do NOT alter the architecture definition below.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)\n",
        "\n",
        "def load_dataset(\n",
        "    split: str,\n",
        "    *,\n",
        "    is_training: bool,\n",
        "    batch_size: int,\n",
        ") -> Iterator[tuple]:\n",
        "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
        "  ds = tfds.load('cifar10', split=split, as_supervised=True).cache().repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "@jax.jit\n",
        "def compute_loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
        "  x, y = batch\n",
        "  logits = net.apply(params, batch)\n",
        "  labels = jax.nn.one_hot(y, 10)\n",
        "  predictions = jax.numpy.argmax(jax.nn.softmax(logits), 1)\n",
        "  # TODO: add code below to compute the l2_loss variable\n",
        "  l2_loss = 0.5 * (predictions - y)**2\n",
        "  weighted_l2_loss = 0.5 * l2_loss\n",
        "  softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "  return softmax_xent - (1e-4 * l2_loss) # hack needed to produce scalar for TypeError: Gradient only defined for scalar-output functions. Output had shape: (1000,). \n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def compute_accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  predictions = net.apply(params, batch)\n",
        "  _, y = batch\n",
        "\n",
        "  # TODO: add code below to compute the accuracy over the batch.\n",
        "  accuracy = y - predictions\n",
        "  return accuracy\n",
        "\n",
        "@jax.jit\n",
        "def update(\n",
        "    params: hk.Params,\n",
        "    opt_state: optax.OptState,\n",
        "    batch: Batch,\n",
        ") -> Tuple[hk.Params, optax.OptState]:\n",
        "  diff = jax.grad(compute_loss)\n",
        "  print(params)\n",
        "  print(batch)\n",
        "  grads = diff(params, batch)\n",
        "  updates, opt_state = opt.update(grads, opt_state)\n",
        "  new_params = optax.apply_updates(params, updates)\n",
        "  return new_params, opt_state\n",
        "\n",
        "@jax.jit\n",
        "def ema_update(params, avg_params):\n",
        "  return optax.incremental_update(params, avg_params, step_size=0.001)\n",
        "\n",
        "\n",
        "def normalize(images):\n",
        "  mean = np.asarray(CIFAR10_MEAN)\n",
        "  std = np.asarray(CIFAR10_STD)\n",
        "  x = images.astype(jnp.int8) / 255.\n",
        "  x /- mean\n",
        "  x /= std\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5iI930cIjzM"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "Q4-HuMSH_Cbw",
        "outputId": "0d7a3f49-b44c-4239-9ac8-113f07b10acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  param = init(shape, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-94c72e20bf04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         donated_invars=donated_invars, inline=inline, keep_unused=keep_unused)\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1938\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1954\u001b[0m   \u001b[0mfun_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    234\u001b[0m   compiled_fun = xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 235\u001b[0;31m                               keep_unused, *arg_specs)\n\u001b[0m\u001b[1;32m    236\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001b[0;32m--> 343\u001b[0;31m                               keep_unused, *arg_specs).compile().unsafe_call\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mlower_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, always_lower, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     jaxpr, out_type, consts = pe.trace_to_jaxpr_final2(\n\u001b[0;32m--> 429\u001b[0;31m         fun, pe.debug_info_final(fun, \"jit\"))\n\u001b[0m\u001b[1;32m    430\u001b[0m   \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_final2\u001b[0;34m(fun, debug_info)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic2\u001b[0;34m(fun, main, debug_info)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0min_tracers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-6a8ce097bb5e>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# TODO: add code below to compute the accuracy over the batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    589\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rejected_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4712\u001b[0;31m       raise TypeError(f\"unsupported operand type(s) for {opchar}: \"\n\u001b[0m\u001b[1;32m   4713\u001b[0m                       f\"{type(args[0]).__name__!r} and {type(args[1]).__name__!r}\")\n",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: unsupported operand type(s) for -: 'tuple' and 'DynamicJaxprTracer'\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-94c72e20bf04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     val_accuracy, test_accuracy = jax.device_get(\n",
            "\u001b[0;32m<ipython-input-63-6a8ce097bb5e>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# TODO: add code below to compute the accuracy over the batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4710\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rejected_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4712\u001b[0;31m       raise TypeError(f\"unsupported operand type(s) for {opchar}: \"\n\u001b[0m\u001b[1;32m   4713\u001b[0m                       f\"{type(args[0]).__name__!r} and {type(args[1]).__name__!r}\")\n\u001b[1;32m   4714\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'DynamicJaxprTracer'"
          ]
        }
      ],
      "source": [
        "net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "\n",
        "# Do not change learning rate\n",
        "opt = optax.adam(1e-3)\n",
        "\n",
        "train = load_dataset(\"train[80%:]\", is_training=True, batch_size=1000)\n",
        "validation = load_dataset(\"train[0%:80%]\", is_training=False, batch_size=10000)\n",
        "test = load_dataset(\"test\", is_training=False, batch_size=10000)\n",
        "\n",
        "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "# Do not alter the number of steps\n",
        "for step in range(10001):\n",
        "  if step % 1000 == 0:\n",
        "    val_accuracy = compute_accuracy(avg_params, next(validation))\n",
        "    test_accuracy = compute_accuracy(avg_params, next(test))\n",
        "    val_accuracy, test_accuracy = jax.device_get(\n",
        "        (val_accuracy, test_accuracy))\n",
        "    print(f\"[Step {step}] Validation / Test accuracy: \"\n",
        "          f\"{val_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "\n",
        "  params, opt_state = update(params, opt_state, next(train))\n",
        "  avg_params = ema_update(params, avg_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWQhbV-MPQA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQmOspeD0jCh"
      },
      "source": [
        "## Coding Challenge Part 2: Compression through Low Rank Approximation (8 points)\n",
        "\n",
        "In this section, you will add code to compute the low rank approximation and to compute evaluation metrics. We will evaluate whether the low rank approximation allows for speed up in inference time. We define inference time as the average time to compute the prediction for all examples in the test set.\n",
        "\n",
        "* [**4 points**] You will need to add code to define both the compute_eval_metrics and rank_approximated weight function. \n",
        "* [**4 points**] Q4 and Q5 are worth 2 points each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdZqO7W_KSX8"
      },
      "outputs": [],
      "source": [
        "def compute_eval_metrics(params, batch, n_samples):\n",
        "# TODO: add code to compute the time for inference.\n",
        "  duration_list = []\n",
        "  accuracy_list = []\n",
        "  for _ in range(n_samples):\n",
        "    start = 0.0\n",
        "    # TODO: add code to correctly compute the accuracy on a given batch.\n",
        "    acc = compute_accuracy(params, batch)\n",
        "    duration = 1.0\n",
        "    duration_list.append(duration)\n",
        "    accuracy_list.append(acc)\n",
        "\n",
        "  return accuracy_list, duration_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8U8Nlp9IS4q"
      },
      "outputs": [],
      "source": [
        "def rank_approximated_weight(weight: jnp.ndarray, rank_fraction: float):\n",
        "  # TODO: replace the code below with code to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "  u = jax.random.normal(jax.random.PRNGKey(42), shape=weight.shape)\n",
        "  size = weight.shape[1]\n",
        "  v = jax.random.normal(jax.random.PRNGKey(42), shape=(size,size))\n",
        "  \n",
        "  return u, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvm9InR4JG4F"
      },
      "source": [
        "### Evaluations at different ranks\n",
        "\n",
        "The code below first replaces the weights with the low rank factorizations at different rank fractions. For each modified net, we compute the new eval accuracy. Firstly, add code for the rank_approximated_weight and add code to correctly compute the time for inference (the duration)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEjLxaDPEGEY",
        "outputId": "edd85550-b1c9-4000-c4fd-3d56df28489b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at 1.0\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.000.\n",
            "Rank Fraction / Duration: 1.00 / 1.0000.\n",
            "Evaluating the model at 0.9\n",
            "Rank Fraction / Test accuracy: 0.90 / 0.000.\n",
            "Rank Fraction / Duration: 0.90 / 1.0000.\n",
            "Evaluating the model at 0.8\n",
            "Rank Fraction / Test accuracy: 0.80 / 0.000.\n",
            "Rank Fraction / Duration: 0.80 / 1.0000.\n",
            "Evaluating the model at 0.7000000000000001\n",
            "Rank Fraction / Test accuracy: 0.70 / 0.000.\n",
            "Rank Fraction / Duration: 0.70 / 1.0000.\n",
            "Evaluating the model at 0.6000000000000001\n",
            "Rank Fraction / Test accuracy: 0.60 / 0.000.\n",
            "Rank Fraction / Duration: 0.60 / 1.0000.\n",
            "Evaluating the model at 0.5000000000000001\n",
            "Rank Fraction / Test accuracy: 0.50 / 0.000.\n",
            "Rank Fraction / Duration: 0.50 / 1.0000.\n",
            "Evaluating the model at 0.40000000000000013\n",
            "Rank Fraction / Test accuracy: 0.40 / 0.000.\n",
            "Rank Fraction / Duration: 0.40 / 1.0000.\n",
            "Evaluating the model at 0.30000000000000016\n",
            "Rank Fraction / Test accuracy: 0.30 / 0.000.\n",
            "Rank Fraction / Duration: 0.30 / 1.0000.\n",
            "Evaluating the model at 0.20000000000000018\n",
            "Rank Fraction / Test accuracy: 0.20 / 0.000.\n",
            "Rank Fraction / Duration: 0.20 / 1.0000.\n",
            "Evaluating the model at 0.1000000000000002\n",
            "Rank Fraction / Test accuracy: 0.10 / 0.000.\n",
            "Rank Fraction / Duration: 0.10 / 1.0000.\n"
          ]
        }
      ],
      "source": [
        "rank_truncated_params = deepcopy(params)\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "\n",
        "  print(f\"Evaluating the model at {rank_fraction}\")\n",
        "  for layer in params.keys():\n",
        "    if 'conv' in layer:\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    # TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    rank_truncated_params[layer]['w'] = u@v\n",
        "\n",
        "  test_batch = next(test)\n",
        "  # we compute metrics over 50 samples to reduce noise in the measurement.\n",
        "  n_samples = 50\n",
        "  # TODO: complete coding the compute_eval_metrics function to compute latency 50 seperate times given the batch passed to compute_eval_metrics. Return the average across all latencies you store.\n",
        "  test_accuracy, latency = compute_eval_metrics(rank_truncated_params, next(test), n_samples)\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(latency):.4f}.\")\n",
        "  ranks_and_times.append((rank_fraction, np.mean(latency)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzyvqIr38eWw"
      },
      "source": [
        "### Q4: What do you observe as the relationship between rank fraction and test accuracy?\n",
        "\n",
        "Plot this relationship showing accuracy (y-axis) vs rank percentage of the matrix (x-axis). You should use the ranks_and_accuracies list computed above.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCdYJ6lSEKM9"
      },
      "outputs": [],
      "source": [
        "## TODO: add your code below to plot the relationship between time and test set accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRkI8rAO5UYe"
      },
      "source": [
        "### Q5: Does replacing the weight matrix with the low factor matrix result in latency speed ups?\n",
        "\n",
        "Plot the relationship of time (y-axis) vs rank percentage (x-axis). To do so add code to compute the ranks_and_times list.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7jlMYxhi7E-"
      },
      "outputs": [],
      "source": [
        "## TODO: add your code below to plot the relationship between time and rank percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR3JTDWb2QII"
      },
      "source": [
        "## Coding Challenge Part 3: Perform evaluations on the dataset in factorized space. (4 points)\n",
        "\n",
        "In this section, you will perform evaluations on the dataset in factorized space.\n",
        "\n",
        "* [**4 points**] 2 pts for question 6 and question 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OctdUxerSZut"
      },
      "outputs": [],
      "source": [
        "def low_rank_net_fn(batch: Batch, rank: float) -> jnp.ndarray:\n",
        "  \n",
        "  x = normalize(batch[0])\n",
        "  total_input_dim = np.prod(x.shape[1:])\n",
        "\n",
        "  # Do not alter the architecture code.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(int(rank * min(total_input_dim, 3000)), with_bias=False),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False), \n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False), \n",
        "      hk.Linear(2000), jax.nn.relu,      \n",
        "      hk.Linear(int(rank * 1000), with_bias=False), \n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 10), with_bias=False),\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi2TN_WV-jgZ",
        "outputId": "60e28a22-c9d7-4fbe-b778-4a036e14fb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at1.00\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.000.\n",
            "Rank Fraction / Duration: 1.00 / 1.0000.\n",
            "Evaluating the model at0.90\n",
            "Rank Fraction / Test accuracy: 0.90 / 0.000.\n",
            "Rank Fraction / Duration: 0.90 / 1.0000.\n",
            "Evaluating the model at0.80\n",
            "Rank Fraction / Test accuracy: 0.80 / 0.000.\n",
            "Rank Fraction / Duration: 0.80 / 1.0000.\n",
            "Evaluating the model at0.70\n",
            "Rank Fraction / Test accuracy: 0.70 / 0.000.\n",
            "Rank Fraction / Duration: 0.70 / 1.0000.\n",
            "Evaluating the model at0.60\n",
            "Rank Fraction / Test accuracy: 0.60 / 0.000.\n",
            "Rank Fraction / Duration: 0.60 / 1.0000.\n",
            "Evaluating the model at0.50\n",
            "Rank Fraction / Test accuracy: 0.50 / 0.000.\n",
            "Rank Fraction / Duration: 0.50 / 1.0000.\n",
            "Evaluating the model at0.40\n",
            "Rank Fraction / Test accuracy: 0.40 / 0.000.\n",
            "Rank Fraction / Duration: 0.40 / 1.0000.\n",
            "Evaluating the model at0.30\n",
            "Rank Fraction / Test accuracy: 0.30 / 0.000.\n",
            "Rank Fraction / Duration: 0.30 / 1.0000.\n",
            "Evaluating the model at0.20\n",
            "Rank Fraction / Test accuracy: 0.20 / 0.000.\n",
            "Rank Fraction / Duration: 0.20 / 1.0000.\n",
            "Evaluating the model at0.10\n",
            "Rank Fraction / Test accuracy: 0.10 / 0.000.\n",
            "Rank Fraction / Duration: 0.10 / 1.0000.\n"
          ]
        }
      ],
      "source": [
        "vanilla_to_low_rank_map = {\n",
        "    'conv2_d': 'conv2_d',\n",
        "    'conv2_d_1': 'conv2_d_1',\n",
        "    'linear': ['linear', 'linear_1'],\n",
        "    'linear_1': ['linear_2', 'linear_3'],\n",
        "    'linear_2': ['linear_4', 'linear_5'],\n",
        "    'linear_3': ['linear_6', 'linear_7'],\n",
        "    'linear_4': ['linear_8', 'linear_9']\n",
        "}\n",
        "\n",
        "\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "  low_rank_net_fn_partial = partial(low_rank_net_fn, rank=rank_fraction)\n",
        "  net = hk.without_apply_rng(hk.transform(low_rank_net_fn_partial)) \n",
        "  low_rank_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "\n",
        "  print(f\"Evaluating the model at\" f\"{rank_fraction:.2f}\")\n",
        "\n",
        "  for layer in vanilla_to_low_rank_map.keys():\n",
        "    if 'conv' in layer:\n",
        "      low_rank_params[layer] = params[layer]\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    # TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][0]]['w'] = u\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['w'] = v\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['b'] = params[layer]['b']\n",
        "  \n",
        "  # TODO: modify the compute_eval_metrics function below to compute the time taken for inference.\n",
        "  test_accuracy, duration = compute_eval_metrics(low_rank_params, next(test), 50)\n",
        "  ranks_and_times.append((rank_fraction, np.mean(duration)))\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(duration):.4f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObBn-Pf_996r"
      },
      "source": [
        "### Q6: Plot a curve showing time vs rank percentage of the matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0bJJFL4LM7q"
      },
      "outputs": [],
      "source": [
        "# TODO: add code to plot the relationship between time vs percentage rank of the matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "313ALwDu93k1"
      },
      "source": [
        "### Q7: What do you observe between time and the percentage rank of the matrix.\n",
        "\n",
        "### Put your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcBKkogM6uV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEAu9Vu-0rWX"
      },
      "source": [
        "## Coding Challenge Part 4: Take this Further (10 bonus points)\n",
        "\n",
        "This part of the challenge is designed to be open ended. If you wanted to show some more skills, here is your chance to shine. We include two options below -- **only do one of the options**:\n",
        "\n",
        "**Option 1:** Implement a change that isn't SVD but minimizes inference latency while preserving accuracy. Can you outperform SVD? \n",
        "\n",
        "\n",
        "\n",
        "**Option 2:** Improve the quality of code for this takehome. Pretend you are reviewing a peer and add comments to cells with suggestions of how to improve the code quality. Try and make your comments action orientated and precise. \n",
        "\n",
        "\n",
        "**For Option 1, DO NOT alter the previous code sections, instead add any new code below. You should not need to add new code for Option 2, instead just add comments to cells.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoN-IhY9hNQE"
      },
      "outputs": [],
      "source": [
        "# TODO: add code for option 1 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq2zcXoRNkYx"
      },
      "source": [
        "## You have made it to the end of the challenge!\n",
        "\n",
        "Before you submit your completed challenge document, please make sure to **save and pin your revisions** before submitting a link to your submission via the [Cohere For AI Scholars Program Application.](https://jobs.lever.co/cohere/) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-v-iHTH3nasL",
        "UHGqpn3tkFRL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}