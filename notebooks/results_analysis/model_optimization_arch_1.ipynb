{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnt7mLbzahUQ",
        "outputId": "82493171-5ad4-4b80-e05a-205cc9951123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=b6f0ca693dda3a066d8d362a3b73792cbc2493c3274e24ba6a3e7aaa76ba3377\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, appdirs, tensorflow-model-optimization, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 tensorflow-model-optimization-0.7.3 wandb-0.14.0\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow-model-optimization wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iQ_voM5yahUR"
      },
      "outputs": [],
      "source": [
        "# utils functions\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import datetime \n",
        "import numpy as np\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def load_data(run, artifact_name = \"phcd_paper_splits_tfds\") -> List[tf.data.Dataset]:\n",
        "    \"\"\"\n",
        "    Downloads datasets from a wandb artifact and loads them into a list of tf.data.Datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    artifact = run.use_artifact(f\"master-thesis/{artifact_name}:latest\")\n",
        "    artifact_dir = pathlib.Path(\n",
        "        f\"./artifacts/{artifact.name.replace(':', '-')}\"\n",
        "    ).resolve()\n",
        "    if not artifact_dir.exists():\n",
        "        artifact_dir = artifact.download()\n",
        "        artifact_dir = pathlib.Path(artifact_dir).resolve()\n",
        "\n",
        "    # if tf.__version__ minor is less than 10, use\n",
        "    # tf.data.experimental.load instead of tf.data.Dataset.load\n",
        "\n",
        "    if int(tf.__version__.split(\".\")[1]) < 10:\n",
        "        load_function = tf.data.experimental.load\n",
        "    else:\n",
        "        load_function = tf.data.Dataset.load\n",
        "    \n",
        "    output_list = []\n",
        "    for split in [\"train\", \"test\", \"val\"]:\n",
        "        ds = load_function(str(artifact_dir / split), compression=\"GZIP\")\n",
        "        output_list.append(ds)\n",
        "    \n",
        "    return output_list\n",
        "\n",
        "def get_readable_class_labels(subset = 'phcd_paper'):\n",
        "    if subset == 'phcd_paper':\n",
        "        return ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c',\n",
        "        'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
        "        'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C',\n",
        "        'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P',\n",
        "        'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'ą', 'ć', 'ę',\n",
        "        'ł', 'ń', 'ó', 'ś', 'ź', 'ż', 'Ą', 'Ć', 'Ę', 'Ł', 'Ń', 'Ó', 'Ś',\n",
        "        'Ź', 'Ż', '+', '-', ':', ';', '$', '!', '?', '@', '.']\n",
        "    elif subset == 'uppercase':\n",
        "        return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
        "        'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Ą', 'Ć', \n",
        "        'Ę', 'Ł', 'Ń', 'Ó', 'Ś', 'Ź', 'Ż']\n",
        "    elif subset == 'lowercase':\n",
        "        return ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ą', 'ć',\n",
        "        'ę', 'ł', 'ń', 'ó', 'ś', 'ź', 'ż']\n",
        "    elif subset == 'numbers':\n",
        "        return ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    elif subset == 'uppercase_no_diacritics':\n",
        "        return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "        'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "    elif subset == 'lowercase_no_diacritics':\n",
        "        return ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "def calculate_accuracy_per_class(model, test_dataset, test_dataset_name):\n",
        "    '''\n",
        "    Calculates the accuracy per class for a given model and test dataset.\n",
        "\n",
        "    Returns dict with class labels as keys and accuracy as values.\n",
        "    '''\n",
        "        \n",
        "    y_pred = model.predict(test_dataset)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    # get labels\n",
        "    y_true = test_dataset.map(lambda x, y: y).as_numpy_iterator()\n",
        "    y_true = np.concatenate(list(y_true))\n",
        "    # calculate accuracy per class\n",
        "    labels = get_readable_class_labels(test_dataset_name)\n",
        "    class_accuracy = np.zeros(len(labels))\n",
        "    for i, label in enumerate(labels):\n",
        "        class_accuracy[i] = np.sum(y_pred[y_true == i] == i) / np.sum(y_true == i)\n",
        "    return { label: acc for label, acc in zip(labels, class_accuracy) }\n",
        "    \n",
        "\n",
        "def plot_accuracy_per_class(class_accuracy_dict):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    labels = list(class_accuracy_dict.keys())\n",
        "    class_accuracy = list(class_accuracy_dict.values())\n",
        "    plt.bar(labels, class_accuracy)\n",
        "    plt.xticks(labels)\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy per class\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def accuracy_table(class_accuracy_dict):\n",
        "    labels = list(class_accuracy_dict.keys())\n",
        "    class_accuracy = list(class_accuracy_dict.values())\n",
        "    return wandb.Table(columns=[\"Class\", \"Accuracy\"], data=list(zip(labels, class_accuracy)))\n",
        "\n",
        "def get_number_of_classes(ds: tf.data.Dataset) -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of classes in a dataset.\n",
        "    \"\"\"\n",
        "    labels_iterator= ds.map(lambda x, y: y).as_numpy_iterator()\n",
        "    labels = np.concatenate(list(labels_iterator))\n",
        "    return len(np.unique(labels))\n",
        "\n",
        "def get_number_of_examples(ds: tf.data.Dataset) -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of examples in a dataset.\n",
        "    \"\"\"\n",
        "    return sum(1 for _ in ds)\n",
        "\n",
        "def preprocess_dataset(ds: tf.data.Dataset, batch_size: int, cache: bool = True) -> tf.data.Dataset:\n",
        "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))  # normalize\n",
        "    ds = ds.unbatch().batch(batch_size)\n",
        "    if cache:\n",
        "        ds = ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def calculate_model_compressed_size_on_disk(path: str) -> int:\n",
        "    compressed_path = path + \".zip\"\n",
        "    with zipfile.ZipFile(compressed_path, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "        f.write(path)\n",
        "    return pathlib.Path(compressed_path).stat().st_size    \n",
        "\n",
        "def calculate_model_size_on_disk(path: str) -> int:\n",
        "    return pathlib.Path(path).stat().st_size\n",
        "\n",
        "def calculate_model_num_parameters(model: tf.keras.Model) -> int:\n",
        "    return model.count_params()\n",
        "\n",
        "def calculate_model_flops(summary) -> float:\n",
        "    # from run.summary get GFLOPs or GFLOPS whichever is available\n",
        "    if \"GFLOPs\" in summary.keys():\n",
        "        return summary.get(\"GFLOPs\")\n",
        "    elif \"GFLOPS\" in summary.keys():\n",
        "        return summary.get(\"GFLOPS\")\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(15,7))\n",
        "    plt.suptitle(title)\n",
        "    \n",
        "    plt.subplot(121)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='val')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.subplot(122)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='val')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "eC0ZiLAgahUT",
        "outputId": "f704bbcc-a414-436c-effd-f1f95e66c240"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "\n",
        "project_name = \"master-thesis\"\n",
        "run_name = \"architecture-1\"\n",
        "\n",
        "def get_runs(project_name, run_name):\n",
        "    \"\"\"\n",
        "    Returns all runs with a given name in a given project.\n",
        "    \"\"\"\n",
        "    api = wandb.Api()\n",
        "    runs = api.runs(\n",
        "        project_name, {\n",
        "            \"$and\": [\n",
        "                {\"displayName\": run_name},\n",
        "                {\"state\": \"finished\"},\n",
        "                {\"tags\": \"phcd_paper_splits_tfds\"}\n",
        "                ]\n",
        "            })\n",
        "    return [run.id for run in runs]\n",
        "\n",
        "def get_model_from_run(run_id, project_name=\"master-thesis\"):\n",
        "    # from project run_id artifacts get file_name\n",
        "    api = wandb.Api()\n",
        "    run = api.run(f\"{project_name}/{run_id}\")\n",
        "    # download file config.yaml\n",
        "    run.file(\"config.yaml\").download(replace=True)\n",
        "    artifact = run.file(\"model_baseline.h5\").download(replace=True)\n",
        "    model = tf.keras.models.load_model(artifact.name, compile=False)\n",
        "    return model, pathlib.Path(artifact.name)\n",
        "\n",
        "run_ids = get_runs(project_name, run_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aObrSCFoahUU",
        "outputId": "125de754-e7ec-41f1-8023-79f1f2614a78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgratkadlafana\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.14.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/wiktor/code/master-thesis/notebooks/results_analysis/wandb/run-20230320_212538-1z1o4hjn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/gratkadlafana/master-thesis/runs/1z1o4hjn\" target=\"_blank\">daily-deluge-461</a></strong> to <a href=\"https://wandb.ai/gratkadlafana/master-thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   9 of 9 files downloaded.  \n",
            "2023-03-20 21:25:41.448351: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2023-03-20 21:25:41.448374: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wiktor-on-linux): /proc/driver/nvidia/version does not exist\n",
            "2023-03-20 21:25:41.448578: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "defaults = dict(\n",
        "    batch_size=32*2,\n",
        "    epochs=60,    \n",
        "    optimizer=\"adam\"\n",
        ")\n",
        "\n",
        "artifact_base_name = \"phcd_paper\"\n",
        "artifact_name = f\"{artifact_base_name}_splits_tfds\" # \"phcd_paper_splits_tfds\n",
        "arch_short_name = \"arch-1\"\n",
        "run = wandb.init(project=\"master-thesis\", job_type=\"model-optimization\",  config=defaults, tags=[\"optimization\"])\n",
        "\n",
        "# hyperparameters\n",
        "epochs = wandb.config.epochs\n",
        "bs = wandb.config.batch_size\n",
        "\n",
        "ds_train, ds_test, ds_val = load_data(run, artifact_name=artifact_name)\n",
        "\n",
        "num_classes = get_number_of_classes(ds_val)\n",
        "\n",
        "ds_train_non_normalized = ds_train.unbatch().batch(64).take(2000).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_test_non_normalized = ds_test.unbatch().batch(64).take(1743).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "ds_train = preprocess_dataset(ds_train, batch_size=bs)\n",
        "ds_val = preprocess_dataset(ds_val, batch_size=bs)\n",
        "ds_test = preprocess_dataset(ds_test, batch_size=bs, cache=False).take(1743).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crSKPDssahUU"
      },
      "source": [
        "# before optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FQR1wwNAahUV"
      },
      "outputs": [],
      "source": [
        "def save_dataset_as_tfrecords(ds: tf.data.Dataset, path):\n",
        "    def serialize_example(image, label):\n",
        "        image = tf.io.serialize_tensor(image)\n",
        "        label = tf.io.serialize_tensor(label)\n",
        "        feature = {\n",
        "            \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.numpy()])),\n",
        "            \"label\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[label.numpy()])),\n",
        "        }\n",
        "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        return example_proto.SerializeToString()\n",
        "\n",
        "    writer = tf.data.experimental.TFRecordWriter(path)\n",
        "    writer.write(ds.map(serialize_example))\n",
        "\n",
        "def benchmark(bench_model, bench_model_path, bench_dataset):\n",
        "    test_loss, test_acc = bench_model.evaluate(bench_dataset)\n",
        "    num_parameters = calculate_model_num_parameters(bench_model)\n",
        "    compressed_disk_size = calculate_model_compressed_size_on_disk(bench_model_path)\n",
        "\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    \n",
        "    print(f\"Number of parameters: {num_parameters}\")\n",
        "    print(f\"Compressed disk size (MB): {compressed_disk_size / 1e6}\")\n",
        "    return test_acc, num_parameters, compressed_disk_size\n",
        "\n",
        "def benchmark_tflite(bench_model, bench_model_path, bench_dataset):\n",
        "    test_loss, test_acc = bench_model.evaluate(bench_dataset)\n",
        "    num_parameters = calculate_model_num_parameters(bench_model)\n",
        "    compressed_disk_size = calculate_model_compressed_size_on_disk(bench_model_path)\n",
        "    \n",
        "    print(f\"Test loss: {test_loss}\")\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    \n",
        "    print(f\"Number of parameters: {num_parameters}\")\n",
        "    print(f\"Compressed disk size (MB): {compressed_disk_size / 1e6}\")\n",
        "    return test_acc, num_parameters, compressed_disk_size\n",
        "\n",
        "def plot_results(acc, num_params, dsk_size):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    data = [acc, num_params, dsk_size]\n",
        "    # boxplots\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        # draw boxplot with seaborn\n",
        "        sns.boxplot(data[i], ax=ax)\n",
        "        # add title\n",
        "        ax.set_title(f\"{['Accuracy', 'Number of parameters', 'Compressed disk size'][i]}\")\n",
        "\n",
        "    # super title\n",
        "    fig.suptitle(\"Pruning results - accuracy, # of parameters, compressed disk size\", fontsize=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPnn0tGYahUW"
      },
      "source": [
        "# Optimization - pruning & quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qGmdS8A7ahUW"
      },
      "outputs": [],
      "source": [
        "# for evaluating tflite models\n",
        "def evaluate_model(interpreter, test_dataset, int8_model=False):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a TensorFlow Lite model on a given test dataset.\n",
        "\n",
        "    Args:\n",
        "        interpreter (tf.lite.Interpreter): A TensorFlow Lite interpreter object with already allocated tensors.\n",
        "        test_dataset (tf.data.Dataset): A TensorFlow dataset object containing test images and labels.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (accuracy, loss) with the model accuracy and loss on the test dataset.\n",
        "    \"\"\"\n",
        "    # Prepare the input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    input_shape = input_details[0]['shape']\n",
        "    input_tensor_index = input_details[0]['index']\n",
        "    output_tensor_index = output_details[0]['index']\n",
        "\n",
        "    # Run the evaluation\n",
        "    #total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for images, labels in tqdm.tqdm(test_dataset, desc=\"Evaluating model\"):\n",
        "        # Resize the images to match the input tensor shape\n",
        "        images = tf.image.resize(images, input_shape[1:3])\n",
        "\n",
        "        # Set the input tensor value\n",
        "        if int8_model:\n",
        "            interpreter.set_tensor(input_tensor_index, images.numpy().astype(np.int8))\n",
        "        else:\n",
        "            interpreter.set_tensor(input_tensor_index, images)\n",
        "\n",
        "        # Run the inference\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Get the output tensor value\n",
        "        output = interpreter.get_tensor(output_tensor_index)\n",
        "\n",
        "        # Compute the batch loss and accuracy\n",
        "        #batch_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, output)\n",
        "        batch_accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels, output)\n",
        "\n",
        "        # Update the total loss and accuracy\n",
        "        #total_loss += tf.reduce_sum(batch_loss)\n",
        "        total_accuracy += tf.reduce_sum(batch_accuracy)\n",
        "        num_batches += 1\n",
        "\n",
        "    # Compute the average loss and accuracy\n",
        "    #average_loss = total_loss / (num_batches * input_shape[0])\n",
        "    average_accuracy = total_accuracy / (num_batches * input_shape[0])\n",
        "\n",
        "    return average_accuracy.numpy() #, average_loss.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cR5QvOjahUX",
        "outputId": "cac6d4ce-7df1-4469-9929-e80e2237d535"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rRuns:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run id: u1ezrh04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1743/1743 [==============================] - 6s 3ms/step - loss: 0.2758 - accuracy: 0.9384\n",
            "Test accuracy: 0.9384053945541382\n",
            "Number of parameters: 1779161\n",
            "Compressed disk size (MB): 6.70464\n",
            "Base model accuracy:  0.9384053945541382\n",
            "Fitting quantization aware model\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    179/Unknown - 4s 9ms/step - loss: 0.2799 - accuracy: 0.8968"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "import tqdm\n",
        "\n",
        "results_columns = [\"run_id\", \"optimization_type\",  \"accuracy\", \"num_parameters\", \"compressed_disk_size\"]\n",
        "results = pd.DataFrame(columns=results_columns)\n",
        "do_pruning = False\n",
        "\n",
        "\n",
        "for run_id in tqdm.tqdm(run_ids, desc=\"Runs\"):\n",
        "  print(f\"Run id: {run_id}\")\n",
        "  model, model_path = get_model_from_run(run_id, project_name)\n",
        "  model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "  \n",
        "  base_acc, base_num_param, base_compressed_disk_size = benchmark(model, str(model_path), ds_test) \n",
        "  \n",
        "  base_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"baseline\", base_acc, base_num_param, base_compressed_disk_size]])\n",
        "  results = pd.concat([results, base_results])\n",
        "\n",
        "  print(\"Base model accuracy: \", base_acc)\n",
        "\n",
        "\n",
        "  if do_pruning:\n",
        "    # pruning\n",
        "    pruning_epochs = 5\n",
        "    batch_size = 64\n",
        "    num_train_samples = sum(1 for _ in ds_train)\n",
        "    end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * pruning_epochs\n",
        "    print('End step: ' + str(end_step))\n",
        "\n",
        "    pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.05, final_sparsity=0.45, begin_step=0, end_step=end_step),\n",
        "    }\n",
        "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "    \n",
        "    model_sparse = prune_low_magnitude(model, **pruning_params)\n",
        "    model_sparse.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "    sparse_model_filename = f\"{run_id}_model_sparse.h5\"\n",
        "    print(\"Pruning model...\")\n",
        "    history = model_sparse.fit(\n",
        "        ds_train,\n",
        "        epochs=pruning_epochs,\n",
        "        validation_data=ds_val,\n",
        "        callbacks=[\n",
        "          tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "          # checkpoint\n",
        "          tf.keras.callbacks.ModelCheckpoint(\n",
        "              filepath=sparse_model_filename,\n",
        "              save_weights_only=False,\n",
        "              monitor=\"val_accuracy\",\n",
        "              mode=\"max\",\n",
        "              save_best_only=True,\n",
        "          ),\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    # plot history\n",
        "    plot_history(history, \"Pruning\")\n",
        "    plt.show()\n",
        "    #tf.keras.models.save_model(model_sparse, 'model_sparse.h5', include_optimizer=False)\n",
        "\n",
        "    test_acc, num_param, compressed_disk_size = benchmark(model_sparse, sparse_model_filename, ds_test)\n",
        "    print(\"Pruned model accuracy: \", test_acc)\n",
        "    sparse_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"pruning\", test_acc, num_param, compressed_disk_size]])\n",
        "    results = pd.concat([results, sparse_results])\n",
        "    # send model to wandb\n",
        "    wandb.save(sparse_model_filename)\n",
        "\n",
        "    del model\n",
        "    del model_sparse\n",
        "\n",
        "  \n",
        "  # quantization\n",
        "  model, model_path = get_model_from_run(run_id, project_name)\n",
        "  model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "  quantization_epochs = 2\n",
        "\n",
        "  quantize_model = tfmot.quantization.keras.quantize_model\n",
        "  model_quant = quantize_model(model)\n",
        "  model_quant.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  quantization_aware_model_filename = f\"{run_id}_model_quant.h5\"\n",
        "  print(\"Fitting quantization aware model\")\n",
        "  history = model_quant.fit(\n",
        "      ds_train,\n",
        "      epochs=quantization_epochs,\n",
        "      validation_data=ds_val,\n",
        "  )\n",
        "\n",
        "  # plot history\n",
        "  plot_history(history, \"Quantization\")\n",
        "  tf.keras.models.save_model(model_quant, quantization_aware_model_filename, include_optimizer=False)\n",
        "\n",
        "  test_acc, num_param, compressed_disk_size = benchmark(model_quant, quantization_aware_model_filename, ds_test)\n",
        "  print(\"Quantization aware model accuracy: \", test_acc)\n",
        "\n",
        "  quant_aware_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"quantization_aware\", test_acc, num_param, compressed_disk_size]])\n",
        "  results = pd.concat([results, quant_aware_results])\n",
        "\n",
        "  # ------------------ TF Lite ------------------------\n",
        "\n",
        "  tflite_models_dir = pathlib.Path(\"./models/\")\n",
        "  tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  dynamic_range_model_file = tflite_models_dir / f\"{run_id}_{arch_short_name}_dynamic_range.tflite\"\n",
        "  fp16_model_file = tflite_models_dir / f\"{run_id}_{arch_short_name}_fp16.tflite\"\n",
        "  int8_model_file = tflite_models_dir / f\"{run_id}_{arch_short_name}_int8.tflite\"\n",
        "\n",
        "  def representative_dataset_gen():\n",
        "    for input_value, _ in ds_train_non_normalized:\n",
        "      yield [input_value]\n",
        "\n",
        "  # dynamic range\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model_quant)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  model_quant_dynamic_range = converter.convert()\n",
        "  dynamic_range_model_file.write_bytes(model_quant_dynamic_range)\n",
        "\n",
        "  # quantization fp16\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model_quant)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.target_spec.supported_types = [tf.float16]\n",
        "  converter.representative_dataset = representative_dataset_gen\n",
        "  model_quant_fp16 = converter.convert()\n",
        "  fp16_model_file.write_bytes(model_quant_fp16)\n",
        "\n",
        "  # quantization int8\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model_quant)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.representative_dataset = representative_dataset_gen\n",
        "  #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "  #converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "  #converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "  model_quant_int8 = converter.convert()\n",
        "  int8_model_file.write_bytes(model_quant_int8)\n",
        "\n",
        "  # load dynamic range model\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(dynamic_range_model_file))\n",
        "  # set batch size to 64\n",
        "  interpreter.resize_tensor_input(0, [64, 32, 32, 1])\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  print(\"Evaluating dynamic range model\")\n",
        "  test_acc_dynamic_range = evaluate_model(interpreter, ds_test)\n",
        "  compressed_disk_size_dynamic_range = calculate_model_compressed_size_on_disk(str(dynamic_range_model_file))\n",
        "  \n",
        "  print(\"Dynamic range accuracy: \", test_acc_dynamic_range)\n",
        "\n",
        "  dynamic_range_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"dynamic_range\", test_acc_dynamic_range, 0, compressed_disk_size_dynamic_range]])\n",
        "  results = pd.concat([results, dynamic_range_results])\n",
        "\n",
        "\n",
        "  # load fp16 model\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(fp16_model_file))\n",
        "  interpreter.resize_tensor_input(0, [64, 32, 32, 1])\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  print(\"Evaluating fp16 model\")\n",
        "  test_acc_fp16 = evaluate_model(interpreter, ds_test)\n",
        "  \n",
        "  print(\"FP16 accuracy: \", test_acc_fp16)\n",
        "  compressed_disk_size_fp16 = calculate_model_compressed_size_on_disk(str(fp16_model_file))\n",
        "\n",
        "  fp16_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"fp16\", test_acc_fp16, 0, compressed_disk_size_fp16]])\n",
        "  results = pd.concat([results, fp16_results])\n",
        "\n",
        "  # load int8 model\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(int8_model_file))\n",
        "  interpreter.resize_tensor_input(0, [64, 32, 32, 1])\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # evaluate interpreter on ds_test: tf.data.Dataset\n",
        "  print(\"Evaluating int8 model\")\n",
        "  test_acc_int8 = evaluate_model(interpreter, ds_test_non_normalized)\n",
        "  print(\"Int8 accuracy: \", test_acc_int8)\n",
        "  compressed_disk_size_int8 = calculate_model_compressed_size_on_disk(str(int8_model_file))\n",
        "\n",
        "  int8_results = pd.DataFrame(columns=results_columns, data=[[run_id, \"int8\", test_acc_int8, 0, compressed_disk_size_int8]])\n",
        "  results = pd.concat([results, int8_results])\n",
        "\n",
        "results_file = f\"optimalization_results_{arch_short_name}.csv\"\n",
        "results.to_csv(results_file)\n",
        "wandb.save(results_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLPDNVcUahUY"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "\n",
        "sns.boxplot(x='optimization_type', y='accuracy', data=results, ax=ax)\n",
        "\n",
        "ax.set_title('Accuracies by optimalization type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkqi40uyahUZ"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='optimization_type', y='compressed_disk_size', data=results, ax=ax)\n",
        "\n",
        "ax.set_title('Compressed file size by optimalization type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOh1ZCIkahUZ"
      },
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DFeobb8Icyps"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "master-thesis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
