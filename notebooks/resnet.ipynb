{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Residual network\n",
                "\n",
                "This notebook trains the ResNet-20 based on\n",
                "\n",
                "\n",
                "After training, model is serialized and uploaded to W&B project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import wandb\n",
                "import pathlib\n",
                "import shutil\n",
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import List\n",
                "\n",
                "\n",
                "def load_data(run) -> List[tf.data.Dataset]:\n",
                "    \"\"\"\n",
                "    Downloads datasets from a wandb artifact and loads them into a list of tf.data.Datasets.\n",
                "    \"\"\"\n",
                "\n",
                "    artifact_name = f\"letters_splits_tfds\"\n",
                "    artifact = run.use_artifact(f\"master-thesis/{artifact_name}:latest\")\n",
                "    artifact_dir = pathlib.Path(\n",
                "        f\"./artifacts/{artifact.name.replace(':', '-')}\"\n",
                "    ).resolve()\n",
                "    if not artifact_dir.exists():\n",
                "        artifact_dir = artifact.download()\n",
                "        artifact_dir = pathlib.Path(artifact_dir).resolve()\n",
                "\n",
                "    # if tf.__version__ minor is less than 10, use\n",
                "    # tf.data.experimental.load instead of tf.data.Dataset.load\n",
                "\n",
                "    if int(tf.__version__.split(\".\")[1]) < 10:\n",
                "        load_function = tf.data.experimental.load\n",
                "    else:\n",
                "        load_function = tf.data.Dataset.load\n",
                "    \n",
                "    output_list = []\n",
                "    for split in [\"train\", \"test\", \"val\"]:\n",
                "        ds = load_function(str(artifact_dir / split), compression=\"GZIP\")\n",
                "        output_list.append(ds)\n",
                "    \n",
                "    return output_list\n",
                "\n",
                "def get_number_of_classes(ds: tf.data.Dataset) -> int:\n",
                "    \"\"\"\n",
                "    Returns the number of classes in a dataset.\n",
                "    \"\"\"\n",
                "    labels_iterator= ds.map(lambda x, y: y).as_numpy_iterator()\n",
                "    labels = np.concatenate(list(labels_iterator))\n",
                "    return len(np.unique(labels))\n",
                "\n",
                "\n",
                "def preprocess_dataset(ds: tf.data.Dataset, batch_size: int, cache: bool = True) -> tf.data.Dataset:\n",
                "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))  # normalize\n",
                "    ds = ds.unbatch().batch(batch_size)\n",
                "    if cache:\n",
                "        ds = ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "\n",
                "def calculate_model_size_on_disk(path: str) -> int:\n",
                "    return pathlib.Path(path).stat().st_size\n",
                "\n",
                "\n",
                "def calculate_model_num_parameters(model: tf.keras.Model) -> int:\n",
                "    return model.count_params()\n",
                "\n",
                "\n",
                "def calculate_model_flops() -> str:\n",
                "    pass\n",
                "\n",
                "\n",
                "def plot_history(history):\n",
                "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
                "    epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
                "    ax.plot(epochs, history.history[\"accuracy\"], label=\"accuracy\")\n",
                "    ax.plot(epochs, history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
                "    ax.set_xlabel(\"Epoch\")\n",
                "    ax.set_ylabel(\"Accuracy\")\n",
                "    ax.legend(loc=\"lower right\")\n",
                "\n",
                "    plt.show()\n",
                "\n",
                "def evaluate_model(model, ds_test, model_name):\n",
                "    \"\"\"\n",
                "    Evaluate model test loss, accuracy and other characteristics then log to wandb\n",
                "    \"\"\"\n",
                "    flops = wandb.run.summary[\"GFLOPs\"]\n",
                "    disk_size = calculate_model_size_on_disk(f\"./artifacts/{model_name}.h5\")\n",
                "    num_parameters = calculate_model_num_parameters(model)\n",
                "\n",
                "    # evaluate model on ds_test and log to wandb\n",
                "    test_loss, test_acc = model.evaluate(ds_test)\n",
                "\n",
                "    wandb.log(\n",
                "        {\n",
                "            \"test loss\": test_loss,\n",
                "            \"test accuracy\": test_acc,\n",
                "            \"number of parameters\": num_parameters,\n",
                "            \"disk size\": disk_size,\n",
                "            \"model flops\": flops,\n",
                "        }\n",
                "    )\n",
                "\n",
                "\n",
                "def evaluate_diacritics_performance(model, ds_test):\n",
                "    \"\"\"\n",
                "    Evaluate model test loss, accuracy on letters with diacritics then log to wandb\n",
                "    \"\"\"\n",
                "    diacritics = {\n",
                "        62: \"ą\",\n",
                "        63: \"ć\",\n",
                "        64: \"ę\",\n",
                "        65: \"ł\",\n",
                "        66: \"ń\",\n",
                "        67: \"ó\",\n",
                "        68: \"ś\",\n",
                "        69: \"ź\",\n",
                "        70: \"ż\",\n",
                "        71: \"Ą\",\n",
                "        72: \"Ć\",\n",
                "        73: \"Ę\",\n",
                "        74: \"Ł\",\n",
                "        75: \"Ń\",\n",
                "        76: \"Ó\",\n",
                "        77: \"Ś\",\n",
                "        78: \"Ź\",\n",
                "        79: \"Ż\",\n",
                "    }\n",
                "\n",
                "    def calculate_batch_size(dataset):\n",
                "        return next(iter(dataset)).shape[0]\n",
                "\n",
                "    bs = calculate_batch_size(ds_test)\n",
                "\n",
                "    # log test accuracy on these classes separately to wandb\n",
                "    diacritics_acc = {}\n",
                "    for diacritic_label in diacritics.keys():\n",
                "        ds_test_diacritic = ds_test.unbatch().filter(lambda x, y: tf.equal(y, diacritic_label)).batch(bs)\n",
                "        test_loss, test_acc = model.evaluate(ds_test_diacritic)\n",
                "        diacritics_acc[diacritic_label] = {\n",
                "            \"loss\": test_loss,\n",
                "            \"accuracy\": test_acc,\n",
                "            \"label\": diacritics[diacritic_label],\n",
                "        }\n",
                "\n",
                "    wandb.log(diacritics_acc)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Finishing last run (ID:xfa551tn) before initializing another..."
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "wandb: ERROR Error while calling W&B API: run gratkadlafana/master-thesis/xfa551tn was previously created and deleted; try a new run name (<Response [409]>)\n",
                        "Thread SenderThread:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 26, in wrapper\n",
                        "    return func(*args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 1592, in upsert_run\n",
                        "    response = self.gql(\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 213, in gql\n",
                        "    ret = self._retry_gql(\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/retry.py\", line 128, in __call__\n",
                        "    result = self._call_fn(*args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 241, in execute\n",
                        "    return self.client.execute(*args, **kwargs)  # type: ignore\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
                        "    result = self._get_result(document, *args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
                        "    return self.transport.execute(document, *args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 39, in execute\n",
                        "    request.raise_for_status()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
                        "    raise HTTPError(http_error_msg, response=self)\n",
                        "requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://api.wandb.ai/graphql\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
                        "    self._run()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
                        "    self._process(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 329, in _process\n",
                        "    self._sm.send(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 341, in send\n",
                        "    send_handler(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 363, in send_request\n",
                        "    send_handler(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 607, in send_request_defer\n",
                        "    self.debounce(final=True)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 510, in debounce\n",
                        "    self._maybe_update_config(always=final)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 487, in _maybe_update_config\n",
                        "    self._debounce_config()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 516, in _debounce_config\n",
                        "    self._api.upsert_run(\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 28, in wrapper\n",
                        "    raise CommError(err.response, err)\n",
                        "wandb.errors.CommError: <Response [409]>\n",
                        "wandb: ERROR Internal wandb error: file data was not synced\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Problem at: /tmp/ipykernel_1401/3709027441.py 11 <module>\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Traceback (most recent call last):\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2079, in _atexit_cleanup\n",
                        "    self._on_finish()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2308, in _on_finish\n",
                        "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 288, in wait\n",
                        "    on_probe(probe_handle)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2273, in _on_probe_exit\n",
                        "    result = handle.wait(timeout=0)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 271, in wait\n",
                        "    raise MailboxError(\"transport failed\")\n",
                        "wandb.errors.MailboxError: transport failed\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
                        "    run = wi.init()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 550, in init\n",
                        "    self._wl._global_run_stack[-1].finish()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 370, in wrapper\n",
                        "    return func(self, *args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 333, in wrapper\n",
                        "    return func(self, *args, **kwargs)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1835, in finish\n",
                        "    return self._finish(exit_code, quiet)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1850, in _finish\n",
                        "    self._atexit_cleanup(exit_code=exit_code)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2090, in _atexit_cleanup\n",
                        "    self._backend.cleanup()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/backend/backend.py\", line 259, in cleanup\n",
                        "    self.interface.join()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 629, in join\n",
                        "    super().join()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 742, in join\n",
                        "    _ = self._communicate_shutdown()\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 552, in _communicate_shutdown\n",
                        "    _ = self._communicate(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 285, in _communicate\n",
                        "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 60, in _communicate_async\n",
                        "    future = self._router.send_and_receive(rec, local=local)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n",
                        "    self._send_message(rec)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n",
                        "    self._sock_client.send_record_communicate(record)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n",
                        "    self.send_server_request(server_req)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
                        "    self._send_message(msg)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
                        "    self._sendall_with_error_handle(header + data)\n",
                        "  File \"/home/wiktor/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
                        "    sent = self._sock.send(data)\n",
                        "BrokenPipeError: [Errno 32] Broken pipe\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
                    ]
                },
                {
                    "ename": "Exception",
                    "evalue": "problem",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mMailboxError\u001b[0m                              Traceback (most recent call last)",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2079\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2079\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_finish()\n\u001b[1;32m   2080\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m ki:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2308\u001b[0m, in \u001b[0;36mRun._on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_footer_exit_status_info(\n\u001b[1;32m   2305\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exit_code, settings\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings, printer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_printer\n\u001b[1;32m   2306\u001b[0m )\n\u001b[0;32m-> 2308\u001b[0m _ \u001b[39m=\u001b[39m exit_handle\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, on_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_progress_exit)\n\u001b[1;32m   2310\u001b[0m \u001b[39m# dispatch all our final requests\u001b[39;00m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:288\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m on_probe \u001b[39mand\u001b[39;00m probe_handle:\n\u001b[0;32m--> 288\u001b[0m     on_probe(probe_handle)\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m on_progress \u001b[39mand\u001b[39;00m progress_handle:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2273\u001b[0m, in \u001b[0;36mRun._on_probe_exit\u001b[0;34m(self, probe_handle)\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[39mif\u001b[39;00m handle:\n\u001b[0;32m-> 2273\u001b[0m     result \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   2274\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:271\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface\u001b[39m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mraise\u001b[39;00m MailboxError(\u001b[39m\"\u001b[39m\u001b[39mtransport failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m found, abandoned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slot\u001b[39m.\u001b[39m_get_and_clear(timeout\u001b[39m=\u001b[39mwait_timeout)\n",
                        "\u001b[0;31mMailboxError\u001b[0m: transport failed",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1108\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1108\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1109\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:550\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m     ipython\u001b[39m.\u001b[39mdisplay_html(\n\u001b[1;32m    547\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinishing last run (ID:\u001b[39m\u001b[39m{\u001b[39;00mlast_id\u001b[39m}\u001b[39;00m\u001b[39m) before initializing another...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 550\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wl\u001b[39m.\u001b[39;49m_global_run_stack[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mfinish()\n\u001b[1;32m    552\u001b[0m \u001b[39mif\u001b[39;00m jupyter:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:370\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mDummy()\n\u001b[0;32m--> 370\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:333\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_attaching \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1835\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m \n\u001b[1;32m   1828\u001b[0m \u001b[39mThis is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[39m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finish(exit_code, quiet)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1850\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         hook\u001b[39m.\u001b[39mcall()\n\u001b[0;32m-> 1850\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_atexit_cleanup(exit_code\u001b[39m=\u001b[39;49mexit_code)\n\u001b[1;32m   1851\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl\u001b[39m.\u001b[39m_global_run_stack) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2090\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2089\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_console_stop()\n\u001b[0;32m-> 2090\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mcleanup()\n\u001b[1;32m   2091\u001b[0m logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mProblem finishing run\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/backend/backend.py:259\u001b[0m, in \u001b[0;36mBackend.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterface:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_process:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:629\u001b[0m, in \u001b[0;36mInterfaceShared.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_router:\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:742\u001b[0m, in \u001b[0;36mInterfaceBase.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate_shutdown()\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:552\u001b[0m, in \u001b[0;36mInterfaceShared._communicate_shutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_record(request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 552\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(record)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:285\u001b[0m, in \u001b[0;36mInterfaceShared._communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_communicate\u001b[39m(\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39m, rec: pb\u001b[39m.\u001b[39mRecord, timeout: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, local: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[pb\u001b[39m.\u001b[39mResult]:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate_async(rec, local\u001b[39m=\u001b[39;49mlocal)\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39mtimeout)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:60\u001b[0m, in \u001b[0;36mInterfaceSock._communicate_async\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe wandb backend process has shutdown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m future \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_router\u001b[39m.\u001b[39;49msend_and_receive(rec, local\u001b[39m=\u001b[39;49mlocal)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m future\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/router.py:94\u001b[0m, in \u001b[0;36mMessageRouter.send_and_receive\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pending_reqs[rec\u001b[39m.\u001b[39muuid] \u001b[39m=\u001b[39m future\n\u001b[0;32m---> 94\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(rec)\n\u001b[1;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m future\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/interface/router_sock.py:36\u001b[0m, in \u001b[0;36mMessageSockRouter._send_message\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_send_message\u001b[39m(\u001b[39mself\u001b[39m, record: \u001b[39m\"\u001b[39m\u001b[39mpb.Record\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock_client\u001b[39m.\u001b[39;49msend_record_communicate(record)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:216\u001b[0m, in \u001b[0;36mSockClient.send_record_communicate\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    215\u001b[0m server_req\u001b[39m.\u001b[39mrecord_communicate\u001b[39m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_server_request(server_req)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_server_request\u001b[39m(\u001b[39mself\u001b[39m, msg: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(msg)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sendall_with_error_handle(header \u001b[39m+\u001b[39;49m data)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[39m# sent equal to 0 indicates a closed socket\u001b[39;00m\n",
                        "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m RESNET_DEPTHS \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m3\u001b[39m]\n\u001b[1;32m     10\u001b[0m MODEL_NAME \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresnet-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m(RESNET_DEPTHS)\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m2\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m run \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmaster-thesis\u001b[39;49m\u001b[39m\"\u001b[39;49m, job_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49mMODEL_NAME, config\u001b[39m=\u001b[39;49mdefaults,)\n\u001b[1;32m     13\u001b[0m \u001b[39m# hyperparameters\u001b[39;00m\n\u001b[1;32m     15\u001b[0m opt_name \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moptimizer\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1145\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[39mif\u001b[39;00m except_exit:\n\u001b[1;32m   1144\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1145\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
                        "\u001b[0;31mException\u001b[0m: problem"
                    ]
                }
            ],
            "source": [
                "defaults = dict(\n",
                "    batch_size=32*4,\n",
                "    epochs=100,    \n",
                "    optimizer=\"sgd\",\n",
                "    learning_rate=0.001,\n",
                "    momentum=0.9,\n",
                ")\n",
                "\n",
                "RESNET_DEPTHS = [3, 4, 6, 3]\n",
                "MODEL_NAME = f\"resnet-{sum(RESNET_DEPTHS) + 2}\"\n",
                "run = wandb.init(project=\"master-thesis\", job_type=\"training\", name=MODEL_NAME, config=defaults,)\n",
                "\n",
                "# hyperparameters\n",
                "\n",
                "opt_name = wandb.config.optimizer\n",
                "lr = wandb.config.learning_rate\n",
                "momentum = wandb.config.momentum\n",
                "bs = wandb.config.batch_size\n",
                "epochs = wandb.config.epochs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Num GPUs Available:  0\n",
                        "Available devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
                    ]
                }
            ],
            "source": [
                "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
                "print(\"Available devices: \", tf.config.list_physical_devices())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "There are 89 classes\n",
                        "Training set has 13953 batches\n",
                        "Test set has 1743 batches\n",
                        "Validation set has 1743 batches\n"
                    ]
                }
            ],
            "source": [
                "ds_train, ds_test, ds_val = load_data(run)\n",
                "\n",
                "num_classes = get_number_of_classes(ds_val)\n",
                "\n",
                "print(f\"There are {num_classes} classes\")\n",
                "print(f\"Training set has {len(ds_train)} batches\")\n",
                "print(f\"Test set has {len(ds_test)} batches\")\n",
                "print(f\"Validation set has {len(ds_val)} batches\")\n",
                "\n",
                "ds_train = preprocess_dataset(ds_train, batch_size=bs)\n",
                "ds_val = preprocess_dataset(ds_val, batch_size=bs)\n",
                "ds_test = preprocess_dataset(ds_test, batch_size=bs, cache=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ResidualBlock(tf.keras.layers.Layer):\n",
                "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
                "        super(ResidualBlock, self).__init__(**kwargs)\n",
                "        self.activation = tf.keras.activations.get(activation)\n",
                "        self.main_layers = [\n",
                "            tf.keras.layers.Conv2D(\n",
                "                filters, strides=strides, kernel_size=3, padding=\"same\", use_bias=False\n",
                "            ),\n",
                "            tf.keras.layers.BatchNormalization(),\n",
                "            self.activation,\n",
                "            tf.keras.layers.Conv2D(\n",
                "                filters, strides=1, kernel_size=3, padding=\"same\", use_bias=False\n",
                "            ),\n",
                "            tf.keras.layers.BatchNormalization(),\n",
                "        ]\n",
                "        self.skip_layers = []\n",
                "        if strides > 1:\n",
                "            self.skip_layers = [\n",
                "                tf.keras.layers.Conv2D(\n",
                "                    filters,\n",
                "                    strides=strides,\n",
                "                    kernel_size=1,\n",
                "                    padding=\"same\",\n",
                "                    use_bias=False,\n",
                "                ),\n",
                "                tf.keras.layers.BatchNormalization(),\n",
                "            ]\n",
                "    def get_config(self):\n",
                "        config = super().get_config()\n",
                "        config.update({\n",
                "            'activation': self.activation,\n",
                "            'main_layers': self.main_layers,\n",
                "            'skip_layers': self.skip_layers\n",
                "        })\n",
                "        return config\n",
                "\n",
                "    def call(self, inputs):\n",
                "        x = inputs\n",
                "        for layer in self.main_layers:\n",
                "            x = layer(x)\n",
                "        skip_x = inputs\n",
                "        for layer in self.skip_layers:\n",
                "            skip_x = layer(skip_x)\n",
                "        return self.activation(x + skip_x)\n",
                "\n",
                "\n",
                "class ResNet(tf.keras.Model):\n",
                "    def __init__(\n",
                "        self,\n",
                "        block_design=[3, 4, 6, 3],\n",
                "        input_shape=[32, 32, 1],\n",
                "        num_classes=88,\n",
                "        **kwargs\n",
                "    ):\n",
                "        super(ResNet, self).__init__(**kwargs)\n",
                "        self.num_classes = num_classes\n",
                "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
                "        self.input_conv = tf.keras.models.Sequential(\n",
                "            [\n",
                "                tf.keras.layers.Conv2D(\n",
                "                    64,\n",
                "                    kernel_size=7,\n",
                "                    strides=2,\n",
                "                    input_shape=input_shape,\n",
                "                    padding=\"same\",\n",
                "                ),\n",
                "                tf.keras.layers.BatchNormalization(),\n",
                "                tf.keras.layers.Activation(\"relu\"),\n",
                "                tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"),\n",
                "            ]\n",
                "        )\n",
                "        self.resnet_blocks = tf.keras.models.Sequential()\n",
                "        prev_filters = 64\n",
                "        for filters in np.repeat(np.array([64, 128, 256, 512]), block_design):\n",
                "            strides = 1 if filters == prev_filters else 2\n",
                "            self.resnet_blocks.add(ResidualBlock(filters, strides=strides))\n",
                "            prev_filters = filters\n",
                "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
                "        self.flatten = tf.keras.layers.Flatten()\n",
                "\n",
                "    def call(self, inputs):\n",
                "        x = self.input_conv(inputs)\n",
                "        x = self.resnet_blocks(x)\n",
                "        x = self.avg_pool(x)\n",
                "        x = self.flatten(x)\n",
                "        return self.classifier(x)\n",
                "\n",
                "\n",
                "def get_resnet_model(input_shape, block_design, num_classes) -> tf.keras.Sequential:\n",
                "    model = tf.keras.models.Sequential(\n",
                "        [\n",
                "            tf.keras.layers.Conv2D(\n",
                "                64, kernel_size=7, strides=2, input_shape=input_shape, padding=\"same\"\n",
                "            ),\n",
                "            tf.keras.layers.BatchNormalization(),\n",
                "            tf.keras.layers.Activation(\"relu\"),\n",
                "            tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"),\n",
                "        ]\n",
                "    )\n",
                "    resnet_blocks = tf.keras.models.Sequential()\n",
                "    prev_filters = 64\n",
                "    for filters in np.repeat(np.array([64, 128, 256, 512]), block_design):\n",
                "        strides = 1 if filters == prev_filters else 2\n",
                "        resnet_blocks.add(ResidualBlock(filters, strides=strides))\n",
                "        prev_filters = filters\n",
                "    model.add(resnet_blocks)\n",
                "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
                "    model.add(tf.keras.layers.Flatten())\n",
                "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = get_resnet_model(input_shape=[32, 32, 1], block_design=RESNET_DEPTHS, num_classes=num_classes)\n",
                "\n",
                "opt = tf.keras.optimizers.get({\n",
                "    'class_name': wandb.config.optimizer,\n",
                "    'config': {\n",
                "        'learning_rate': lr,\n",
                "        'momentum': momentum\n",
                "    }\n",
                "})\n",
                "\n",
                "model.compile(\n",
                "    optimizer=opt,\n",
                "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
                "    metrics=[\"accuracy\"],\n",
                ")\n",
                "\n",
                "wandb_callback = wandb.keras.WandbCallback(\n",
                "    save_model=False,\n",
                "    compute_flops=True,\n",
                ")\n",
                "\n",
                "# save the best model\n",
                "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
                "    filepath=f\"./artifacts/{MODEL_NAME}.h5\",\n",
                "    save_weights_only=False,\n",
                "    monitor=\"val_accuracy\",\n",
                "    mode=\"max\",\n",
                "    save_best_only=True,\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    ds_train,\n",
                "    epochs=epochs,\n",
                "    validation_data=ds_val,\n",
                "    callbacks=[wandb_callback, checkpoint_callback],\n",
                ")\n",
                "\n",
                "print(\"Training finished\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_history(history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# evaluate model then log to wandb\n",
                "\n",
                "evaluate_model(model, ds_test, MODEL_NAME)\n",
                "evaluate_diacritics_performance(model, ds_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save artifact to wandb\n",
                "artifact = wandb.Artifact(\n",
                "    name=MODEL_NAME,\n",
                "    type=\"model\"\n",
                ")\n",
                "\n",
                "# save best model to artifact\n",
                "artifact.add_file(f\"./artifacts/{MODEL_NAME}.h5\")\n",
                "run.log_artifact(artifact)\n",
                "run.finish()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8 (main, Dec  2 2022, 12:59:27) [GCC 11.3.0]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "a3cf6db26d87e92fac078aa6971b2d8666aac2a31f8d0d2caf1f374e90c80bd2"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
